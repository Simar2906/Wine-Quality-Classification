{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd038740d3277777e2cd7c6c2cc9d8addf5118fdf3f82b1b39231fd12aeac8aee8b",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "38740d3277777e2cd7c6c2cc9d8addf5118fdf3f82b1b39231fd12aeac8aee8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('datasets_4458_8204_winequality-red.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping Dependant Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = y.reshape(len(y), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Dataset into Test Set and Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[6]\n [5]\n [7]\n [6]\n [5]\n [6]\n [5]\n [6]\n [4]\n [5]\n [5]\n [5]\n [6]\n [5]\n [6]\n [6]\n [7]\n [5]\n [5]\n [4]\n [7]\n [6]\n [6]\n [4]\n [6]\n [5]\n [5]\n [7]\n [5]\n [6]\n [5]\n [6]\n [5]\n [6]\n [7]\n [7]\n [5]\n [6]\n [6]\n [7]\n [5]\n [7]\n [6]\n [6]\n [5]\n [5]\n [6]\n [6]\n [6]\n [5]\n [5]\n [5]\n [6]\n [6]\n [6]\n [5]\n [5]\n [5]\n [6]\n [5]\n [5]\n [6]\n [6]\n [6]\n [5]\n [6]\n [5]\n [5]\n [6]\n [6]\n [6]\n [6]\n [4]\n [6]\n [5]\n [6]\n [5]\n [5]\n [5]\n [6]\n [6]\n [5]\n [6]\n [6]\n [6]\n [5]\n [6]\n [5]\n [5]\n [5]\n [5]\n [6]\n [4]\n [5]\n [7]\n [6]\n [6]\n [5]\n [6]\n [5]\n [8]\n [6]\n [6]\n [6]\n [5]\n [5]\n [5]\n [5]\n [7]\n [5]\n [6]\n [5]\n [7]\n [5]\n [6]\n [6]\n [6]\n [7]\n [6]\n [6]\n [5]\n [7]\n [5]\n [5]\n [6]\n [6]\n [5]\n [5]\n [5]\n [6]\n [6]\n [6]\n [6]\n [6]\n [6]\n [5]\n [6]\n [5]\n [8]\n [5]\n [6]\n [5]\n [6]\n [5]\n [4]\n [6]\n [7]\n [6]\n [5]\n [6]\n [6]\n [5]\n [5]\n [5]\n [6]\n [6]\n [3]\n [6]\n [6]\n [6]\n [6]\n [6]\n [6]\n [6]\n [5]\n [5]\n [6]\n [6]\n [6]\n [6]\n [5]\n [5]\n [5]\n [8]\n [5]\n [6]\n [6]\n [7]\n [7]\n [5]\n [5]\n [7]\n [5]\n [6]\n [6]\n [4]\n [5]\n [6]\n [5]\n [5]\n [6]\n [5]\n [6]\n [6]\n [5]\n [5]\n [5]\n [5]\n [5]\n [5]\n [5]\n [6]\n [6]\n [5]\n [6]\n [6]\n [5]\n [6]\n [7]\n [6]\n [6]\n [6]\n [5]\n [5]\n [5]\n [6]\n [5]\n [6]\n [6]\n [5]\n [5]\n [5]\n [6]\n [6]\n [5]\n [6]\n [6]\n [6]\n [3]\n [6]\n [5]\n [5]\n [7]\n [6]\n [7]\n [6]\n [6]\n [7]\n [7]\n [6]\n [5]\n [6]\n [5]\n [5]\n [6]\n [5]\n [5]\n [5]\n [5]\n [6]\n [5]\n [5]\n [5]\n [6]\n [6]\n [5]\n [5]\n [5]\n [6]\n [7]\n [5]\n [6]\n [5]\n [6]\n [5]\n [4]\n [5]\n [5]\n [6]\n [7]\n [6]\n [5]\n [5]\n [4]\n [5]\n [6]\n [7]\n [6]\n [6]\n [7]\n [5]\n [7]\n [5]\n [6]\n [6]\n [5]\n [5]\n [5]\n [6]\n [6]\n [5]\n [6]\n [6]\n [6]\n [5]\n [6]\n [6]\n [5]\n [6]\n [5]\n [6]\n [5]\n [6]\n [6]\n [6]\n [6]\n [5]\n [5]\n [6]\n [5]\n [5]\n [6]\n [5]\n [5]\n [5]\n [6]\n [4]\n [5]\n [4]\n [6]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.fit_transform(X_test)\n",
    "\n",
    "y_train = sc_y.fit_transform(y_train)\n",
    "y_test = sc_y.fit_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SVR Model On Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Python\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  return f(**kwargs)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel = 'rbf')\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Test Set Results and Comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "y_pred = y_pred.reshape(len(y_pred), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[6.         5.18704203]\n [5.         5.13566432]\n [7.         6.92750945]\n [6.         4.82266403]\n [5.         5.93076789]\n [6.         5.15341262]\n [5.         5.03581956]\n [6.         5.82537685]\n [4.         5.11279564]\n [5.         5.02909887]\n [5.         4.94764799]\n [5.         5.36464956]\n [6.         5.5223583 ]\n [5.         5.37910332]\n [6.         5.42895647]\n [6.         6.21603754]\n [7.         6.80943611]\n [5.         5.27513654]\n [5.         5.39029298]\n [4.         5.2571662 ]\n [7.         5.93687483]\n [6.         5.22703372]\n [6.         5.5939851 ]\n [4.         5.64231643]\n [6.         5.37067678]\n [5.         5.12769018]\n [5.         5.14336341]\n [7.         6.72833462]\n [5.         4.99165024]\n [6.         5.94190318]\n [5.         5.78895461]\n [6.         5.79312761]\n [5.         5.5734269 ]\n [6.         5.39689961]\n [7.         5.91435039]\n [7.         5.95693135]\n [5.         5.25083889]\n [6.         5.78882644]\n [6.         6.08039115]\n [7.         5.80850892]\n [5.         5.13443808]\n [7.         6.56691034]\n [6.         6.23794809]\n [6.         6.38090806]\n [5.         5.83078228]\n [5.         5.08844078]\n [6.         5.04784348]\n [6.         5.6439675 ]\n [6.         5.04765893]\n [5.         5.79894267]\n [5.         4.83511256]\n [5.         5.12748552]\n [6.         6.00684327]\n [6.         6.10848534]\n [6.         5.41390208]\n [5.         5.15990062]\n [5.         4.92251443]\n [5.         5.0887558 ]\n [6.         6.66288947]\n [5.         5.59950465]\n [5.         5.07047308]\n [6.         5.76035162]\n [6.         5.95053254]\n [6.         5.69922156]\n [5.         5.08271183]\n [6.         6.08410051]\n [5.         5.09145948]\n [5.         5.10511661]\n [6.         6.20123824]\n [6.         6.01534542]\n [6.         5.1850709 ]\n [6.         5.2188969 ]\n [4.         4.94384831]\n [6.         5.17903135]\n [5.         5.51183844]\n [6.         5.9272517 ]\n [5.         5.31794996]\n [5.         5.03158693]\n [5.         5.05748949]\n [6.         6.48171391]\n [6.         5.51191505]\n [5.         5.06254106]\n [6.         5.73486518]\n [6.         5.73709407]\n [6.         5.4538915 ]\n [5.         5.61536444]\n [6.         5.9111073 ]\n [5.         4.85032884]\n [5.         5.32920037]\n [5.         4.91313533]\n [5.         4.92463274]\n [6.         5.0725284 ]\n [4.         5.48114359]\n [5.         5.16671977]\n [7.         6.02643372]\n [6.         5.1850709 ]\n [6.         6.36580914]\n [5.         4.9241631 ]\n [6.         5.51273455]\n [5.         5.84459701]\n [8.         6.52144826]\n [6.         5.80678066]\n [6.         5.69937934]\n [6.         6.09193723]\n [5.         5.12967118]\n [5.         5.21470493]\n [5.         5.12967118]\n [5.         5.29031807]\n [7.         5.82857051]\n [5.         5.18849851]\n [6.         6.01177266]\n [5.         4.90246243]\n [7.         6.41926742]\n [5.         5.33047316]\n [6.         5.74047166]\n [6.         5.79432602]\n [6.         5.70418861]\n [7.         6.64161817]\n [6.         5.88171749]\n [6.         5.5939851 ]\n [5.         5.06441116]\n [7.         5.78071952]\n [5.         5.21427093]\n [5.         4.98792994]\n [6.         5.95678068]\n [6.         6.5795374 ]\n [5.         4.95496834]\n [5.         5.15247075]\n [5.         5.82038548]\n [6.         6.64371081]\n [6.         5.16217999]\n [6.         5.18564357]\n [6.         5.90643718]\n [6.         5.71589681]\n [6.         5.97785816]\n [5.         4.98763047]\n [6.         6.06688047]\n [5.         5.14152149]\n [8.         6.23243936]\n [5.         5.00524561]\n [6.         5.3413441 ]\n [5.         5.02572845]\n [6.         5.04784348]\n [5.         5.43280244]\n [4.         5.09160758]\n [6.         5.71085585]\n [7.         6.41926742]\n [6.         6.50629922]\n [5.         6.22003853]\n [6.         5.08009237]\n [6.         5.94480693]\n [5.         5.54045127]\n [5.         5.29031807]\n [5.         5.35771905]\n [6.         5.88159149]\n [6.         5.47144859]\n [3.         5.15901302]\n [6.         5.27509201]\n [6.         5.92238713]\n [6.         5.9180528 ]\n [6.         5.55857137]\n [6.         5.48540966]\n [6.         6.30736384]\n [6.         5.12673501]\n [5.         5.54575582]\n [5.         5.06929613]\n [6.         5.71217748]\n [6.         5.99348199]\n [6.         5.30778039]\n [6.         5.99304688]\n [5.         5.87895456]\n [5.         5.58009631]\n [5.         4.92245055]\n [8.         6.86382948]\n [5.         5.58419321]\n [6.         5.97673917]\n [6.         5.87517555]\n [7.         6.6366542 ]\n [7.         5.88299949]\n [5.         5.02965199]\n [5.         4.94545629]\n [7.         6.86853234]\n [5.         5.4314607 ]\n [6.         6.02832905]\n [6.         6.07799117]\n [4.         5.11271322]\n [5.         5.46338585]\n [6.         5.69937934]\n [5.         5.0649651 ]\n [5.         6.04238892]\n [6.         6.28399123]\n [5.         5.44854759]\n [6.         5.58081267]\n [6.         5.4898431 ]\n [5.         5.04573975]\n [5.         5.04978498]\n [5.         4.94764799]\n [5.         5.29186403]\n [5.         5.37925723]\n [5.         5.09914883]\n [5.         4.91405653]\n [6.         6.42410877]\n [6.         5.05366161]\n [5.         5.47837413]\n [6.         5.24998976]\n [6.         4.9121036 ]\n [5.         4.98982267]\n [6.         6.20452519]\n [7.         5.92638353]\n [6.         5.21889805]\n [6.         5.47681664]\n [6.         5.73865094]\n [5.         5.03708368]\n [5.         6.26597591]\n [5.         4.91943818]\n [6.         5.69461758]\n [5.         5.85182024]\n [6.         6.0438191 ]\n [6.         5.61399219]\n [5.         5.00616115]\n [5.         5.04043673]\n [5.         5.89266572]\n [6.         6.12473389]\n [6.         5.7045513 ]\n [5.         5.63049457]\n [6.         5.83582707]\n [6.         6.01955225]\n [6.         5.61158813]\n [3.         5.53655123]\n [6.         5.32373045]\n [5.         4.96056647]\n [5.         5.9234701 ]\n [7.         5.02222201]\n [6.         5.51988366]\n [7.         6.33282372]\n [6.         5.719673  ]\n [6.         6.36029066]\n [7.         6.88291966]\n [7.         6.10825405]\n [6.         6.08053105]\n [5.         5.52982224]\n [6.         5.36714215]\n [5.         4.92834895]\n [5.         4.9320234 ]\n [6.         6.05983103]\n [5.         5.03064554]\n [5.         5.57833167]\n [5.         5.04920681]\n [5.         5.1337675 ]\n [6.         5.92680929]\n [5.         5.06077993]\n [5.         5.22703213]\n [5.         5.03925761]\n [6.         5.19383793]\n [6.         5.44551187]\n [5.         5.58500063]\n [5.         5.06440584]\n [5.         4.96993028]\n [6.         5.03819308]\n [7.         5.93884099]\n [5.         5.46022756]\n [6.         6.45313897]\n [5.         5.2669462 ]\n [6.         5.64757748]\n [5.         5.24704081]\n [4.         5.0130601 ]\n [5.         5.17569436]\n [5.         4.97277601]\n [6.         5.70920281]\n [7.         5.78876983]\n [6.         5.12408239]\n [5.         5.65896047]\n [5.         5.11666802]\n [4.         5.79788549]\n [5.         6.17871903]\n [6.         5.90204282]\n [7.         6.28601063]\n [6.         5.02361909]\n [6.         6.06572826]\n [7.         6.46851821]\n [5.         5.01464639]\n [7.         6.21103175]\n [5.         5.65896047]\n [6.         6.15780603]\n [6.         5.86962286]\n [5.         4.99839427]\n [5.         4.97076601]\n [5.         5.14294055]\n [6.         6.36929203]\n [6.         5.81113965]\n [5.         5.70656791]\n [6.         5.17772128]\n [6.         6.18305476]\n [6.         5.62345397]\n [5.         5.22453857]\n [6.         5.7830763 ]\n [6.         5.29699674]\n [5.         4.93977807]\n [6.         5.04982928]\n [5.         5.07991249]\n [6.         5.98227507]\n [5.         4.81929097]\n [6.         5.11146813]\n [6.         5.40057262]\n [6.         6.04612047]\n [6.         5.78655172]\n [5.         5.17051469]\n [5.         4.96009733]\n [6.         5.24403425]\n [5.         5.05906496]\n [5.         5.35562834]\n [6.         6.13218717]\n [5.         5.18790984]\n [5.         4.9241631 ]\n [5.         5.0334456 ]\n [6.         6.0805277 ]\n [4.         5.88580331]\n [5.         6.11779709]\n [4.         5.29958564]\n [6.         6.38507653]]\n"
     ]
    }
   ],
   "source": [
    "print(np.concatenate((sc_y.inverse_transform(y_test),sc_y.inverse_transform(y_pred)), 1))"
   ]
  },
  {
   "source": [
    "## Comparing Rounded Results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[6. 5.]\n",
      " [5. 5.]\n",
      " [7. 7.]\n",
      " [6. 5.]\n",
      " [5. 6.]\n",
      " [6. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [4. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [6. 5.]\n",
      " [6. 6.]\n",
      " [7. 7.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [4. 5.]\n",
      " [7. 6.]\n",
      " [6. 5.]\n",
      " [6. 6.]\n",
      " [4. 6.]\n",
      " [6. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [7. 7.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [5. 6.]\n",
      " [6. 6.]\n",
      " [5. 6.]\n",
      " [6. 5.]\n",
      " [7. 6.]\n",
      " [7. 6.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [7. 6.]\n",
      " [5. 5.]\n",
      " [7. 7.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [5. 6.]\n",
      " [5. 5.]\n",
      " [6. 5.]\n",
      " [6. 6.]\n",
      " [6. 5.]\n",
      " [5. 6.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [6. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 7.]\n",
      " [5. 6.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [6. 5.]\n",
      " [6. 5.]\n",
      " [4. 5.]\n",
      " [6. 5.]\n",
      " [5. 6.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [6. 5.]\n",
      " [5. 6.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 5.]\n",
      " [4. 5.]\n",
      " [5. 5.]\n",
      " [7. 6.]\n",
      " [6. 5.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [5. 6.]\n",
      " [8. 7.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [7. 6.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [7. 6.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [7. 7.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [7. 6.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [6. 7.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 6.]\n",
      " [6. 7.]\n",
      " [6. 5.]\n",
      " [6. 5.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [8. 6.]\n",
      " [5. 5.]\n",
      " [6. 5.]\n",
      " [5. 5.]\n",
      " [6. 5.]\n",
      " [5. 5.]\n",
      " [4. 5.]\n",
      " [6. 6.]\n",
      " [7. 6.]\n",
      " [6. 7.]\n",
      " [5. 6.]\n",
      " [6. 5.]\n",
      " [6. 6.]\n",
      " [5. 6.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [6. 5.]\n",
      " [3. 5.]\n",
      " [6. 5.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [6. 5.]\n",
      " [6. 6.]\n",
      " [6. 5.]\n",
      " [5. 6.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [6. 5.]\n",
      " [6. 6.]\n",
      " [5. 6.]\n",
      " [5. 6.]\n",
      " [5. 5.]\n",
      " [8. 7.]\n",
      " [5. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [7. 7.]\n",
      " [7. 6.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [7. 7.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [4. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [5. 6.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [6. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [6. 5.]\n",
      " [5. 5.]\n",
      " [6. 5.]\n",
      " [6. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [7. 6.]\n",
      " [6. 5.]\n",
      " [6. 5.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [5. 6.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [5. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [5. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [3. 6.]\n",
      " [6. 5.]\n",
      " [5. 5.]\n",
      " [5. 6.]\n",
      " [7. 5.]\n",
      " [6. 6.]\n",
      " [7. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [7. 7.]\n",
      " [7. 6.]\n",
      " [6. 6.]\n",
      " [5. 6.]\n",
      " [6. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [5. 6.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 5.]\n",
      " [6. 5.]\n",
      " [5. 6.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 5.]\n",
      " [7. 6.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [4. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [7. 6.]\n",
      " [6. 5.]\n",
      " [5. 6.]\n",
      " [5. 5.]\n",
      " [4. 6.]\n",
      " [5. 6.]\n",
      " [6. 6.]\n",
      " [7. 6.]\n",
      " [6. 5.]\n",
      " [6. 6.]\n",
      " [7. 6.]\n",
      " [5. 5.]\n",
      " [7. 6.]\n",
      " [5. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [5. 6.]\n",
      " [6. 5.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [6. 5.]\n",
      " [5. 5.]\n",
      " [6. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [6. 5.]\n",
      " [6. 5.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [4. 6.]\n",
      " [5. 6.]\n",
      " [4. 5.]\n",
      " [6. 6.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_real = sc_y.inverse_transform(y_pred)\n",
    "y_pred_real = np.round(y_pred_real)\n",
    "print(np.concatenate((sc_y.inverse_transform(y_test), y_pred_real), 1)) "
   ]
  },
  {
   "source": [
    "## Calculating Accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6.0\n5.0\n5.0\n5.0\n7.0\n7.0\n6.0\n5.0\n5.0\n6.0\n6.0\n5.0\n5.0\n5.0\n6.0\n6.0\n4.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n6.0\n6.0\n5.0\n5.0\n6.0\n5.0\n6.0\n6.0\n7.0\n7.0\n5.0\n5.0\n5.0\n5.0\n4.0\n5.0\n7.0\n6.0\n6.0\n5.0\n6.0\n6.0\n4.0\n6.0\n6.0\n5.0\n5.0\n5.0\n5.0\n5.0\n7.0\n7.0\n5.0\n5.0\n6.0\n6.0\n5.0\n6.0\n6.0\n6.0\n5.0\n6.0\n6.0\n5.0\n7.0\n6.0\n7.0\n6.0\n5.0\n5.0\n6.0\n6.0\n6.0\n6.0\n7.0\n6.0\n5.0\n5.0\n7.0\n7.0\n6.0\n6.0\n6.0\n6.0\n5.0\n6.0\n5.0\n5.0\n6.0\n5.0\n6.0\n6.0\n6.0\n5.0\n5.0\n6.0\n5.0\n5.0\n5.0\n5.0\n6.0\n6.0\n6.0\n6.0\n6.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n6.0\n7.0\n5.0\n6.0\n5.0\n5.0\n6.0\n6.0\n6.0\n6.0\n6.0\n6.0\n5.0\n5.0\n6.0\n6.0\n5.0\n5.0\n5.0\n5.0\n6.0\n6.0\n6.0\n6.0\n6.0\n5.0\n6.0\n5.0\n4.0\n5.0\n6.0\n5.0\n5.0\n6.0\n6.0\n6.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n6.0\n6.0\n6.0\n6.0\n5.0\n5.0\n6.0\n6.0\n6.0\n6.0\n6.0\n5.0\n5.0\n6.0\n6.0\n6.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n6.0\n5.0\n4.0\n5.0\n5.0\n5.0\n7.0\n6.0\n6.0\n5.0\n6.0\n6.0\n5.0\n5.0\n6.0\n6.0\n5.0\n6.0\n8.0\n7.0\n6.0\n6.0\n6.0\n6.0\n6.0\n6.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n7.0\n6.0\n5.0\n5.0\n6.0\n6.0\n5.0\n5.0\n7.0\n6.0\n5.0\n5.0\n6.0\n6.0\n6.0\n6.0\n6.0\n6.0\n7.0\n7.0\n6.0\n6.0\n6.0\n6.0\n5.0\n5.0\n7.0\n6.0\n5.0\n5.0\n5.0\n5.0\n6.0\n6.0\n6.0\n7.0\n5.0\n5.0\n5.0\n5.0\n5.0\n6.0\n6.0\n7.0\n6.0\n5.0\n6.0\n5.0\n6.0\n6.0\n6.0\n6.0\n6.0\n6.0\n5.0\n5.0\n6.0\n6.0\n5.0\n5.0\n8.0\n6.0\n5.0\n5.0\n6.0\n5.0\n5.0\n5.0\n6.0\n5.0\n5.0\n5.0\n4.0\n5.0\n6.0\n6.0\n7.0\n6.0\n6.0\n7.0\n5.0\n6.0\n6.0\n5.0\n6.0\n6.0\n5.0\n6.0\n5.0\n5.0\n5.0\n5.0\n6.0\n6.0\n6.0\n5.0\n3.0\n5.0\n6.0\n5.0\n6.0\n6.0\n6.0\n6.0\n6.0\n6.0\n6.0\n5.0\n6.0\n6.0\n6.0\n5.0\n5.0\n6.0\n5.0\n5.0\n6.0\n6.0\n6.0\n6.0\n6.0\n5.0\n6.0\n6.0\n5.0\n6.0\n5.0\n6.0\n5.0\n5.0\n8.0\n7.0\n5.0\n6.0\n6.0\n6.0\n6.0\n6.0\n7.0\n7.0\n7.0\n6.0\n5.0\n5.0\n5.0\n5.0\n7.0\n7.0\n5.0\n5.0\n6.0\n6.0\n6.0\n6.0\n4.0\n5.0\n5.0\n5.0\n6.0\n6.0\n5.0\n5.0\n5.0\n6.0\n6.0\n6.0\n5.0\n5.0\n6.0\n6.0\n6.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n6.0\n6.0\n6.0\n5.0\n5.0\n5.0\n6.0\n5.0\n6.0\n5.0\n5.0\n5.0\n6.0\n6.0\n7.0\n6.0\n6.0\n5.0\n6.0\n5.0\n6.0\n6.0\n5.0\n5.0\n5.0\n6.0\n5.0\n5.0\n6.0\n6.0\n5.0\n6.0\n6.0\n6.0\n6.0\n6.0\n5.0\n5.0\n5.0\n5.0\n5.0\n6.0\n6.0\n6.0\n6.0\n6.0\n5.0\n6.0\n6.0\n6.0\n6.0\n6.0\n6.0\n6.0\n3.0\n6.0\n6.0\n5.0\n5.0\n5.0\n5.0\n6.0\n7.0\n5.0\n6.0\n6.0\n7.0\n6.0\n6.0\n6.0\n6.0\n6.0\n7.0\n7.0\n7.0\n6.0\n6.0\n6.0\n5.0\n6.0\n6.0\n5.0\n5.0\n5.0\n5.0\n5.0\n6.0\n6.0\n5.0\n5.0\n5.0\n6.0\n5.0\n5.0\n5.0\n5.0\n6.0\n6.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n6.0\n5.0\n6.0\n5.0\n5.0\n6.0\n5.0\n5.0\n5.0\n5.0\n6.0\n5.0\n7.0\n6.0\n5.0\n5.0\n6.0\n6.0\n5.0\n5.0\n6.0\n6.0\n5.0\n5.0\n4.0\n5.0\n5.0\n5.0\n5.0\n5.0\n6.0\n6.0\n7.0\n6.0\n6.0\n5.0\n5.0\n6.0\n5.0\n5.0\n4.0\n6.0\n5.0\n6.0\n6.0\n6.0\n7.0\n6.0\n6.0\n5.0\n6.0\n6.0\n7.0\n6.0\n5.0\n5.0\n7.0\n6.0\n5.0\n6.0\n6.0\n6.0\n6.0\n6.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n6.0\n6.0\n6.0\n6.0\n5.0\n6.0\n6.0\n5.0\n6.0\n6.0\n6.0\n6.0\n5.0\n5.0\n6.0\n6.0\n6.0\n5.0\n5.0\n5.0\n6.0\n5.0\n5.0\n5.0\n6.0\n6.0\n5.0\n5.0\n6.0\n5.0\n6.0\n5.0\n6.0\n6.0\n6.0\n6.0\n5.0\n5.0\n5.0\n5.0\n6.0\n5.0\n5.0\n5.0\n5.0\n5.0\n6.0\n6.0\n5.0\n5.0\n5.0\n5.0\n5.0\n5.0\n6.0\n6.0\n4.0\n6.0\n5.0\n6.0\n4.0\n5.0\n6.0\n6.0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for j in range(len(y_test)):\n",
    "    for i in range(0, 1):\n",
    "        print(sc_y.inverse_transform(y_test)[j][i])\n",
    "        print(y_pred_real[j][i])\n",
    "        if(sc_y.inverse_transform(y_test)[j][i] == y_pred_real[j][i]):\n",
    "            #print(y_test[j][i] + ' ' + y_pred_real[j][i])\n",
    "            count = count + 1\n"
   ]
  },
  {
   "source": [
    "## Accuracy for quality prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.64375\n"
     ]
    }
   ],
   "source": [
    "print(count/len(y_test))"
   ]
  }
 ]
}